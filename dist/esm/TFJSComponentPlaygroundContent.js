import{_ as t,a as e}from"./_rollupPluginBabelHelpers-ed8cbb08.js";import{L as n,c as a,h as o}from"./lit-element-51727a0b.js";import{getBasePathWithTrailingSlash as r,defineCustomElement as i}from"./utilities.js";import"./index.js";import"./class-map-d74af20d.js";import"./mwc-snackbar-b8a221fd.js";import"./form-element-300125b4.js";import"./mwc-slider-d35821e3.js";function s(){var t=e(['\n      <p>Try one of the buttons above.</p>\n      <p><strong>&lt;tfjs-component-playground&gt;</strong> is made primarily using LitElement and the Web Components\n      <a href="https://github.com/kherrick/x-face-detector">&lt;x-face-detector&gt;</a>,\n      <a href="https://github.com/kherrick/x-image-classifier">&lt;x-image-classifier&gt;</a>, and\n      <a href="https://github.com/kherrick/x-object-detector">&lt;x-object-detector&gt;</a>. It utilizes redux for\n      routing and central state management, as well as TensorFlow.js with\n      <a href="https://github.com/tensorflow/tfjs/tree/master/tfjs-backend-wasm">a WebAssembly backend</a>. The\n      <a href="https://github.com/tensorflow/tfjs-models/tree/master/mobilenet">mobilenet</a> model from Google is used\n      for the classification of images from <a href=',">a camera</a>,\n      <a href=",">images\n      from the web</a>, or by <a href=",'>dragging\n      and dropping files into the drop zone</a>. The <a href="https://github.com/tensorflow/tfjs-models/tree/master/blazeface">blazeface</a>\n      model is used for face identification with <a href=',">a camera</a>, using\n      urls of <a href=",">\n      images from the web</a>, or by <a href=",'>\n      dragging and dropping files into the drop zone</a>. Similarly, the\n      <a href="https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd">coco-ssd</a> model is used for object\n      identification with <a href=',">a camera</a>, using urls of\n      <a href=","> images\n      from the web</a>, or by <a href=",">dragging\n      and dropping files into the drop zone</a>. All image classification, object, and facial detection is completed\n      client-side.</p>\n    "]);return s=function(){return t},t}function c(){var t=e(["\n      :host {\n        text-align: var(--tfjs-component-playground-text-align, center);\n      }\n\n      a {\n        color: var(--tfjs-component-playground-link-color, blue);\n        text-decoration: var(--tfjs-component-playground-link-text-decoration, underline);\n      }\n\n      a:hover {\n        color: var(--tfjs-component-playground-link-hover-color, darkblue);\n        text-decoration: var(--tfjs-component-playground-link-hover-text-decoration, underline);\n      }\n\n      p {\n        margin: auto;\n        max-width: 360px;\n        padding: 0 1rem;\n      }\n\n      p:first-of-type {\n        margin-bottom: 2rem;\n      }\n\n      p:not(:first-child) {\n\n      }\n    "]);return c=function(){return t},t}class l extends n{static get styles(){return a(c())}static get properties(){return{imgUrl:{type:String}}}constructor(){super(),t(this,"_path",r()),this.snackLabel=""}render(){return o(s(),this._path+"mobilenet/userMediaVideo",this._path+"mobilenet/single/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL2toZXJyaWNrL3RmanMtY29tcG9uZW50LXBsYXlncm91bmQvbWFzdGVyL2Fzc2V0cy9kZW1vLzc=",this._path+"mobilenet/range/0x9999999/domain/github-avatars/3065761",this._path+"blazeface/userMediaVideo",this._path+"blazeface/single/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL2toZXJyaWNrL3RmanMtY29tcG9uZW50LXBsYXlncm91bmQvbWFzdGVyL2Fzc2V0cy9kZW1vLzE=",this._path+"blazeface/range/0x9999999/domain/github-avatars/3065761",this._path+"cocossd/userMediaVideo",this._path+"cocossd/single/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL2toZXJyaWNrL3RmanMtY29tcG9uZW50LXBsYXlncm91bmQvbWFzdGVyL2Fzc2V0cy9kZW1vLzEw",this._path+"cocossd/range/0x9999999/domain/github-avatars/3065761")}}i("tfjs-component-playground-content",l);export{l as TFJSComponentPlaygroundContent};
